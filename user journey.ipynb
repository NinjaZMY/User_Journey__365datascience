{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0797af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the first cleaning function again, as the execution environment is reset between turns.\n",
    "import pandas as pd\n",
    "\n",
    "def remove_page_duplicates(data: pd.DataFrame, target_column: str = 'user_journey') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes sequences of sequentially repeating pages in the user journey strings.\n",
    "\n",
    "    Args:\n",
    "        data: The dataframe containing all the data.\n",
    "        target_column: The name of the column containing the user journey strings.\n",
    "\n",
    "    Returns:\n",
    "        A new dataframe with the cleaned-up journey strings.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    new_df = data.copy()\n",
    "\n",
    "    def clean_journey(journey: str) -> str:\n",
    "        if pd.isna(journey):\n",
    "            return journey\n",
    "\n",
    "        # Split the journey into pages\n",
    "        pages = journey.split('-')\n",
    "        \n",
    "        # Initialize a list for the cleaned journey\n",
    "        cleaned_pages = []\n",
    "        \n",
    "        # Iterate through the pages and keep only if it's different from the last added page\n",
    "        for page in pages:\n",
    "            if not cleaned_pages or page != cleaned_pages[-1]:\n",
    "                cleaned_pages.append(page)\n",
    "        \n",
    "        # Join the pages back into a single string\n",
    "        return '-'.join(cleaned_pages)\n",
    "\n",
    "    # Apply the cleaning function to the target column\n",
    "    new_df[target_column] = new_df[target_column].apply(clean_journey)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "# --- Demo Data and Testing ---\n",
    "\n",
    "# Create demo data to test the function\n",
    "demo_data = pd.DataFrame({\n",
    "    'user_id': [1, 2, 3, 4],\n",
    "    'session_id': [101, 102, 103, 104],\n",
    "    'user_journey': [\n",
    "        \"Homepage-Pricing-Homepage\",              # Should remain unchanged\n",
    "        \"Homepage-Homepage-Homepage-Pricing\",     # Should become \"Homepage-Pricing\"\n",
    "        \"Checkout-Checkout-Review-Review-Final\",  # Should become \"Checkout-Review-Final\"\n",
    "        \"Login-Login-Homepage-Pricing-Login\"      # Should become \"Login-Homepage-Pricing-Login\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Original Demo Data:\")\n",
    "print(demo_data)\n",
    "# Original Demo Data:\n",
    "#    user_id  session_id                           user_journey\n",
    "# 0        1         101              Homepage-Pricing-Homepage\n",
    "# 1        2         102     Homepage-Homepage-Homepage-Pricing\n",
    "# 2        3         103  Checkout-Checkout-Review-Review-Final\n",
    "# 3        4         104     Login-Login-Homepage-Pricing-Login\n",
    "\n",
    "# Call the function on the demo data\n",
    "cleaned_demo_data = remove_page_duplicates(demo_data)\n",
    "\n",
    "print(\"\\nCleaned Demo Data:\")\n",
    "print(cleaned_demo_data)\n",
    "# Cleaned Demo Data:\n",
    "#    user_id  session_id                  user_journey\n",
    "# 0        1         101     Homepage-Pricing-Homepage\n",
    "# 1        2         102              Homepage-Pricing\n",
    "# 2        3         103         Checkout-Review-Final\n",
    "# 3        4         104  Login-Homepage-Pricing-Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the first cleaning function\n",
    "def remove_page_duplicates(data: pd.DataFrame, target_column: str = 'user_journey') -> pd.DataFrame:\n",
    "    # ... (function definition is the same)\n",
    "    new_df = data.copy()\n",
    "    \n",
    "    def clean_journey(journey: str) -> str:\n",
    "        if pd.isna(journey):\n",
    "            return journey\n",
    "        pages = journey.split('-')\n",
    "        cleaned_pages = []\n",
    "        for page in pages:\n",
    "            if not cleaned_pages or page != cleaned_pages[-1]:\n",
    "                cleaned_pages.append(page)\n",
    "        return '-'.join(cleaned_pages)\n",
    "\n",
    "    new_df[target_column] = new_df[target_column].apply(clean_journey)\n",
    "    return new_df\n",
    "\n",
    "# Load the data from the CSV file\n",
    "df_raw = pd.read_csv(\"user_journey_raw.csv\")\n",
    "\n",
    "# Create a subset of the first 100 rows for demonstration\n",
    "df_raw_100 = df_raw.head(100)\n",
    "\n",
    "# Print the 100 rows of the RAW DataFrame\n",
    "print(\"--- 100 Rows of the RAW DataFrame ---\")\n",
    "print(df_raw_100.to_string())\n",
    "\n",
    "# Apply the cleaning function ONLY to the 100-row subset\n",
    "df_cleaned_100 = remove_page_duplicates(df_raw_100)\n",
    "\n",
    "# Print the 100 rows of the cleaned DataFrame\n",
    "print(\"\\n--- 100 Rows of the CLEANED DataFrame (only the subset was cleaned) ---\")\n",
    "print(df_cleaned_100.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d17d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Increase the maximum column width and set display options to ensure full string printing\n",
    "\"\"\" pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 10) \"\"\"\n",
    "\n",
    "# Load the data from the CSV file\n",
    "df_raw = pd.read_csv(\"user_journey_raw.csv\")\n",
    "\n",
    "def group_by(data: pd.DataFrame, group_column: str = 'user_id', target_column: str = 'user_journey', sessions = 'All', count_from: str = 'last') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Groups user journey strings for a given user ID, optionally restricting the number of sessions.\n",
    "    \n",
    "    *Fixes deprecation warning by using .head() and .tail() instead of .apply() for session slicing.*\n",
    "    \"\"\"\n",
    "    new_df = data.copy()\n",
    "\n",
    "    # 1. Sort by group_column and session_id to ensure chronological order within each user\n",
    "    if 'session_id' in new_df.columns:\n",
    "        new_df = new_df.sort_values(by=[group_column, 'session_id'])\n",
    "    else:\n",
    "        new_df = new_df.sort_values(by=[group_column])\n",
    "\n",
    "    # 2. Select the specified number of sessions using head/tail\n",
    "    if isinstance(sessions, int) and sessions > 0:\n",
    "        grouped = new_df.groupby(group_column, group_keys=False)\n",
    "\n",
    "        if count_from == 'first':\n",
    "            new_df = grouped.head(sessions)\n",
    "        elif count_from == 'last':\n",
    "            new_df = grouped.tail(sessions)\n",
    "\n",
    "    # 3. Group and aggregate the journey strings, joining them with a hyphen\n",
    "    grouped_df = new_df.groupby(group_column).agg(\n",
    "        {target_column: lambda x: '-'.join(x.astype(str))}\n",
    "    ).reset_index()\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "    # Print the original demo data (pre-grouped sessions)\n",
    "print(\"--- Original Demo Data (Sessions per User) ---\")\n",
    "print(df_raw[['user_id', 'session_id', 'user_journey']].to_string())\n",
    "# Output (partial, showing User ID 1516 and 3395 for context):\n",
    "#     user_id  session_id                                                  user_journey\n",
    "# 0      1516     2980231                                         Homepage-Log in-Other\n",
    "# 1      1516     2980248                                          Other-Sign up-Log in\n",
    "# 2      1516     2992252                                                        Log in\n",
    "# 3      1516     3070491                                               Homepage-Log in\n",
    "# 4      1516     3709807                                                        Log in\n",
    "# 5      1516     3723132                                                      Checkout\n",
    "# 6      1516     3723365                                                      Checkout\n",
    "# 7      1516     3723382                                                      Checkout\n",
    "# 8      1516     3723427                                                      Checkout\n",
    "# 9      1516     3723483                                                        Coupon\n",
    "# 10     1516     3723508                                                      Checkout\n",
    "# 11     1516     3724778                                                      Checkout\n",
    "# 12     1516     3726160                                                      Checkout\n",
    "# 13     3395     1415870                                                         Other\n",
    "# 14     3395     3645805                                        Pricing-Sign up-Log in\n",
    "# 15     3395     3657408                                              Homepage-Pricing\n",
    "# 16     3395     3712148                                              Pricing-Checkout\n",
    "# 17     3395     3713857                                                      Checkout\n",
    "# ... (and so on for other users)\n",
    "\n",
    "# Print the session count per test user BEFORE grouping\n",
    "print(\"\\n--- Session Count Per User (for test users) ---\")\n",
    "print(df_raw.groupby('user_id')['session_id'].count())\n",
    "# Output:\n",
    "# user_id\n",
    "# 1516     13\n",
    "# 3395      5\n",
    "# 10107    16\n",
    "# 11145    11\n",
    "# 12400     4\n",
    "# Name: session_id, dtype: int64\n",
    "\n",
    "\n",
    "# 1. Test 'All' sessions (Default)\n",
    "df_grouped_all = group_by(df_raw, sessions='All')\n",
    "print(\"\\n--- Test 1: Grouping 'All' Sessions \")\n",
    "print(df_grouped_all)\n",
    "# Output (User 1516):\n",
    "#    user_id                                                                                     user_journey\n",
    "# 0     1516  Homepage-Log in-Other-Other-Sign up-Log in-Log in-Homepage-Log in-Log in-Checkout-Checkout-Checkout-Checkout-Coupon-Checkout-Checkout-Checkout\n",
    "# ...\n",
    "\n",
    "# 2. Test grouping by the 'last' 3 sessions\n",
    "df_grouped_last_3 = group_by(df_raw, sessions=3, count_from='last')\n",
    "print(\"\\n--- Test 2: Grouping the 'Last' 3 Sessions \")\n",
    "print(df_grouped_last_3)\n",
    "# Output (User 1516):\n",
    "#    user_id                 user_journey\n",
    "# 0     1516  Checkout-Checkout-Checkout\n",
    "# ...\n",
    "\n",
    "# 3. Test grouping by the 'first' 2 sessions\n",
    "df_grouped_first_2 = group_by(df_raw, sessions=2, count_from='first')\n",
    "print(\"\\n--- Test 3: Grouping the 'First' 2 Sessions ---\")\n",
    "print(df_grouped_first_2)\n",
    "# Output (User 1516):\n",
    "#    user_id                    user_journey\n",
    "# 0     1516  Homepage-Log in-Other-Other-Sign up-Log in\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec140eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final DataFrame Head (Confirming Column Order) ---\n",
      "   user_id subscription_type                                                                                                                                                                                                                     user_journey\n",
      "0     1516            Annual                                                                                                                                                    Homepage-Log in-Other-Sign up-Log in-Homepage-Log in-Checkout-Coupon-Checkout\n",
      "1     3395            Annual                                                                                                                                                                           Other-Pricing-Sign up-Log in-Homepage-Pricing-Checkout\n",
      "2    10107            Annual  Homepage-Career tracks-Homepage-Career tracks-Sign up-Log in-Homepage-Resources center-Other-Homepage-Career tracks-Courses-Career tracks-Courses-Career tracks-Log in-Homepage-Log in-Checkout-Log in-Checkout-Log in-Checkout\n",
      "3    11145           Monthly                                                                         Homepage-Log in-Homepage-Log in-Homepage-Log in-Homepage-Log in-Homepage-Log in-Homepage-Log in-Homepage-Log in-Homepage-Log in-Homepage-Log in-Checkout\n",
      "4    12400           Monthly                                                                                              Homepage-Career tracks-Sign up-Log in-Other-Career track certificate-Resources center-Homepage-Instructors-Homepage-Log in-Checkout\n",
      "\n",
      "--- Full Pipeline Reordered Execution Complete ---\n",
      "Pipeline Order: Function 2 (group_by) -> Function 3 (remove_pages) -> Function 1 (remove_page_duplicates)\n",
      "Final DataFrame has 1350 rows (one per unique user).\n",
      "Saved cleaned data to user_journey_cleaned_reordered.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set options to display full journey strings (optional, but good practice)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "# --- Function 1: Remove Sequential Page Duplicates ---\n",
    "def remove_page_duplicates(data: pd.DataFrame, target_column: str = 'user_journey') -> pd.DataFrame:\n",
    "    \"\"\"Removes sequences of sequentially repeating pages in the user journey strings.\"\"\"\n",
    "    new_df = data.copy()\n",
    "    def clean_journey(journey: str) -> str:\n",
    "        if pd.isna(journey):\n",
    "            return journey\n",
    "        pages = journey.split('-')\n",
    "        cleaned_pages = []\n",
    "        for page in pages:\n",
    "            if not cleaned_pages or page != cleaned_pages[-1]:\n",
    "                cleaned_pages.append(page)\n",
    "        return '-'.join(cleaned_pages)\n",
    "    new_df[target_column] = new_df[target_column].apply(clean_journey)\n",
    "    return new_df\n",
    "\n",
    "# --- Function 2: Group User Journeys by ID and Session Count (MODIFIED for column order) ---\n",
    "def group_by(data: pd.DataFrame, group_column: str = 'user_id', target_column: str = 'user_journey', sessions = 'All', count_from: str = 'last') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Groups user journey strings for a given user ID, optionally restricting the number of sessions.\n",
    "    Preserves 'subscription_type' and ensures it is the second column (index 1).\n",
    "    \"\"\"\n",
    "    new_df = data.copy()\n",
    "    if 'session_id' in new_df.columns:\n",
    "        new_df = new_df.sort_values(by=[group_column, 'session_id'])\n",
    "    else:\n",
    "        new_df = new_df.sort_values(by=[group_column])\n",
    "\n",
    "    if isinstance(sessions, int) and sessions > 0:\n",
    "        grouped = new_df.groupby(group_column, group_keys=False)\n",
    "        if count_from == 'first':\n",
    "            new_df = grouped.head(sessions)\n",
    "        elif count_from == 'last':\n",
    "            new_df = grouped.tail(sessions)\n",
    "\n",
    "    # MODIFICATION: Explicitly define the aggregation dictionary keys in the desired output order.\n",
    "    agg_dict = {}\n",
    "    if 'subscription_type' in new_df.columns:\n",
    "        # 1. Place 'subscription_type' first in the aggregation dict (it will be column 2 after user_id)\n",
    "        agg_dict['subscription_type'] = 'first'\n",
    "        \n",
    "    # 2. Place 'user_journey' second in the aggregation dict (it will be column 3)\n",
    "    agg_dict[target_column] = lambda x: '-'.join(x.astype(str))\n",
    "        \n",
    "    grouped_df = new_df.groupby(group_column).agg(agg_dict).reset_index()\n",
    "    \n",
    "    # Final check and explicit reordering of columns to ensure user_id, subscription_type, user_journey\n",
    "    # Although agg typically orders by dict keys, explicit selection is safest.\n",
    "    final_cols = [group_column]\n",
    "    if 'subscription_type' in grouped_df.columns:\n",
    "        final_cols.append('subscription_type')\n",
    "    final_cols.append(target_column)\n",
    "\n",
    "    # Return the DataFrame with the correct column order\n",
    "    return grouped_df[final_cols]\n",
    "\n",
    "# --- Function 3: Remove Specific Pages from Journey String (No Change) ---\n",
    "def remove_pages(data: pd.DataFrame, pages: list, target_column: str = 'user_journey') -> pd.DataFrame:\n",
    "    \"\"\"Removes specific pages from the user journey strings in the target column.\"\"\"\n",
    "    new_df = data.copy()\n",
    "    pages_to_remove = set(pages)\n",
    "    def filter_journey(journey: str) -> str:\n",
    "        if pd.isna(journey) or not journey:\n",
    "            return journey\n",
    "        filtered_pages = [page for page in journey.split('-') if page not in pages_to_remove]\n",
    "        return '-'.join(filtered_pages)\n",
    "    new_df[target_column] = new_df[target_column].apply(filter_journey)\n",
    "    return new_df\n",
    "\n",
    "# --- FULL PIPELINE EXECUTION (Order: F2 -> F3 -> F1) ---\n",
    "\n",
    "# Load the raw data\n",
    "df_raw = pd.read_csv(\"user_journey_raw.csv\")\n",
    "\n",
    "# Step 1 (Function 2): Group all sessions, ensuring 'subscription_type' is column 2\n",
    "df_step_2 = group_by(df_raw, sessions='All')\n",
    "\n",
    "# Step 2 (Function 3): Remove specific pages (none yet, as requested)\n",
    "pages_to_exclude = []\n",
    "df_step_3 = remove_pages(df_step_2, pages=pages_to_exclude)\n",
    "\n",
    "# Step 3 (Function 1): Remove sequential duplicates from the final long journey string.\n",
    "df_final = remove_page_duplicates(df_step_3)\n",
    "\n",
    "# 4. Export the final DataFrame to CSV\n",
    "output_filename = 'user_journey_cleaned_reordered.csv'\n",
    "df_final.to_csv(output_filename, index=False)\n",
    "\n",
    "# Inspect the final DataFrame to confirm 'subscription_type' is the second column\n",
    "print(f\"--- Final DataFrame Head (Confirming Column Order) ---\")\n",
    "print(df_final.head().to_string())\n",
    "\n",
    "print(f\"\\n--- Full Pipeline Reordered Execution Complete ---\")\n",
    "print(f\"Pipeline Order: Function 2 (group_by) -> Function 3 (remove_pages) -> Function 1 (remove_page_duplicates)\")\n",
    "print(f\"Final DataFrame has {len(df_final)} rows (one per unique user).\")\n",
    "print(f\"Saved cleaned data to {output_filename}\")\n",
    "\n",
    "# Reset options\n",
    "pd.reset_option('display.max_colwidth')\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.max_rows')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
